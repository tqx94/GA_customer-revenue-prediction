---
title: "revenue_practice"
output: html_document
---

Google revenue analytics: Taken from: https://www.kaggle.com/kailex/r-eda-for-gstore-glm-keras-xgb 


Objective
Loading of packages
```{r, Loading of packages}
packages <- c("dplyr",
              "magrittr",
              "data.table",
              "tidytext",
              "ggplot2",
              "lubridate",
              "reshape2",
              "wordcloud",
              "RColorBrewer",
              "stringr",
              "jsonlite",
              "caret",
              "scales",
              "gridExtra",
              "xgboost",
              "keras")
lapply(packages, require, character.only = TRUE)
#for (i in 2:length(packages))
#{
 # install.packages(packages[i])
#}
```

Loading of data
```{r, loading of packages,cache = TRUE}
test <- read.csv("~/Documents/kaggle/google_analytics_customer_review/test.csv")
train <- read.csv("~/Documents/kaggle/google_analytics_customer_review/train.csv")
```

creating the functions in json
str_c function is faster den trace. 
```{r, flatten data}
flatten_json <- . %>% 
  str_c(., collapse = ",") %>% 
  str_c("[", ., "]") %>% 
  fromJSON(flatten = T)

parse <- . %>% 
  bind_cols(flatten_json(.$device)) %>%
  bind_cols(flatten_json(.$geoNetwork)) %>% 
  bind_cols(flatten_json(.$trafficSource)) %>% 
  bind_cols(flatten_json(.$totals)) %>% 
  select(-device, -geoNetwork, -trafficSource, -totals)

train <- parse(train)
test <- parse (test)
```

Difference between the dataframe -"%<>%" helps to remove one column without assigning 
```{r, features intersection}
setdiff(names(train), names(test))
train %<>% select(-"campaignCode")
```

Finding constant columns, by counting the number of distinct values. 
so if the number of distinct value is 1, we can delete the co
```{r, finding constant columns}
fea_uniq_values <- sapply(train, n_distinct)
fea_del <- names(fea_uniq_values[fea_uniq_values == 1])
train %<>% select(-fea_del)
test %<>% select(-fea_del)
```

Removing NA
```{r, removing NA values}
is_na_val <- function(x) x %in% c("not available in demo dataset", "(not provided)",
                                  "(not set)", "<NA>", "unknown.unknown",  "(none)")

train %<>% mutate_all(funs(ifelse(is_na_val(.), NA, .)))
test %<>% mutate_all(funs(ifelse(is_na_val(.), NA, .)))
```

Transformation to the original representation
```{r, target variable}
train %<>%
  mutate(date = ymd(date),
         hits = as.integer(hits),
         pageviews = as.integer(pageviews),
         bounces = as.integer(bounces),
         newVisits = as.integer(newVisits),
         transactionRevenue = as.numeric(transactionRevenue))
         
test %<>%
  mutate(date = ymd(date),
         hits = as.integer(hits),
         pageviews = as.integer(pageviews),
         bounces = as.integer(bounces),
         newVisits = as.integer(newVisits))       
```

```{r, target variable}
 y <- train$transactionRevenue
train$transactionRevenue <- NULL
summary(y)
y[is.na(y)] <- 0
summary(y)
```


Preprocessing dataset for XGboost
```{r, preprocessing dataset for xgboost}
grp_mean <- function(x, grp) ave(x, grp, FUN = function(x) mean(x, na.rm = TRUE))

idx <- train$date < ymd("20170701")
id <- test[, "fullVisitorId"]
tri <- 1:nrow(train)

tr_te <- train %>%
  bind_rows(test) %>% 
  mutate(year = year(date) %>% factor(),
         wday = wday(date) %>% factor(),
         hour = hour(as_datetime(visitStartTime)) %>% factor(),
         isMobile = ifelse(isMobile, 1L, 0L),
         isTrueDirect = ifelse(isTrueDirect, 1L, 0L),
         adwordsClickInfo.isVideoAd = ifelse(!adwordsClickInfo.isVideoAd, 0L, 1L)) %>% 
  select(-date, -fullVisitorId, -visitId, -sessionId, -hits, -visitStartTime) %>% 
  mutate_if(is.character, factor) %>% 
  mutate(pageviews_mean_vn = grp_mean(pageviews, visitNumber),
         pageviews_mean_country = grp_mean(pageviews, country),
         pageviews_mean_city = grp_mean(pageviews, city),
         pageviews_mean_dom = grp_mean(pageviews, networkDomain),
         pageviews_mean_ref = grp_mean(pageviews, referralPath)) %T>% 
  glimpse()
```

Submission function
```{r, submit function} 
submit <- . %>% 
  tibble::as_tibble() %>% 
  magrittr::set_names("y") %>% 
  dplyr::mutate(y = ifelse(y < 0, 0, expm1(y))) %>% 
  dplyr::bind_cols(id) %>% 
  dplyr::group_by(fullVisitorId) %>% 
  dplyr::summarise(y = log1p(sum(y))) %>% 
  right_join(
    read_csv("../input/sample_submission.csv"), 
    by = "fullVisitorId") %>% 
  dplyr::mutate(PredictedLogRevenue = round(y, 5)) %>% 
  dplyr::select(-y) %>% 
  write_csv(sub)
```

XGboost
```{r, xgboost}
tr_te_xgb <- tr_te %>% 
  mutate_if(is.factor, as.integer)
```

```{r, train using a timebased spilt}
dtest <- xgb.DMatrix(data = data.matrix(tr_te_xgb[-tri, ]))
tr_te_xgb <- tr_te_xgb[tri, ]
dtr <- xgb.DMatrix(data = data.matrix(tr_te_xgb[idx, ]), label = log1p(y[idx]))
dval <- xgb.DMatrix(data = data.matrix(tr_te_xgb[!idx, ]), label = log1p(y[!idx]))
dtrain <- xgb.DMatrix(data = data.matrix(tr_te_xgb), label = log1p(y))
cols <- colnames(tr_te_xgb)
```

Train the model
```{r, train the model}
p <- list(objective = "reg:linear",
          booster = "gbtree",
          eval_metric = "rmse",
          nthread = 4,
          eta = 0.05,
          max_depth = 7,
          min_child_weight = 5,
          gamma = 0,
          subsample = 0.8,
          colsample_bytree = 0.7,
          colsample_bylevel = 0.6,
          nrounds = 2000)

set.seed(0)
m_xgb <- xgb.train(p, dtr, p$nrounds, list(val = dval), print_every_n = 100, early_stopping_rounds = 100)
```

```{r, importance}
xgb.importance(cols, model = m_xgb) %>% 
  xgb.plot.importance(top_n = 25)
```

```{r, prediction}
pred_xgb_tr <- predict(m_xgb, dtrain)
pred_xgb <- predict(m_xgb, dtest) 
sub <- "xgb_gs.csv"
submit(pred_xgb)
```

GLMNET function
```{r, glmnet function}
tr_te_ohe <- tr_te %>% 
  mutate_if(is.factor, fct_explicit_na) %>% 
  mutate_if(is.numeric, funs(ifelse(is.na(.), 0L, .))) %>% 
  mutate_if(is.factor, fct_lump, prop = 0.05) %>% 
  select(-adwordsClickInfo.isVideoAd) %>% 
  model.matrix(~.-1, .) %>% 
  scale() %>% 
  round(4)

X <- tr_te_ohe[tri, ]
X_test <- tr_te_ohe[-tri, ]
rm(tr_te_ohe); invisible(gc())
```

Creating a cv lasso model
```{r, CV lasso model}
m_glm <- cv.glmnet(X, log1p(y), alpha = 0, family="gaussian", 
                   type.measure = "mse", nfolds = 5)
```

```{r, predictions of a Lasso model}
pred_glm_tr <- predict(m_glm, X, s = "lambda.min") %>% c()
pred_glm <- predict(m_glm, X_test, s = "lambda.min") %>% c()
sub <- "glmnet_gs.csv"
submit(pred_glm)

rm(m_glm); invisible(gc())
```

Keras function - Neural net function
```{r, neural net}
m_nn <- keras_model_sequential()
m_nn %>% 
  layer_dense(units = 256, activation = "relu", input_shape = ncol(X)) %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 128, activation = "relu") %>%
  layer_dropout(rate = 0.25) %>%
  layer_dense(units = 1, activation = "linear")
```

compile with apporiate parameters
```{r, app parameters}
m_nn %>% compile(loss = "mean_squared_error",
                 metrics = custom_metric("rmse", function(y_true, y_pred) 
                   k_sqrt(metric_mean_squared_error(y_true, y_pred))),
                 optimizer = optimizer_adadelta())
```

```{r, train the model}
history <- m_nn %>% 
  fit(X, log1p(y), 
      epochs = 50, 
      batch_size = 128, 
      verbose = 0, 
      validation_split = 0.2,
      callbacks = callback_early_stopping(patience = 5))
```

```{r, predictions}
pred_nn_tr <- predict(m_nn, X) %>% c()
pred_nn <- predict(m_nn, X_test) %>% c()
sub <- "keras_gs.csv"
submit(pred_nn)

rm(m_nn, X, X_test); invisible(gc())
```